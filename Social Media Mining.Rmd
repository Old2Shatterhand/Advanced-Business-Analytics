---
title: "Social Media Mining"
author: "Tim Lui"
date: "5/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rtweet)
library(magrittr)
library(purrr)
library(hunspell)
library(pdftools)
library(tidytext)
library(wordcloud)
```

```{r}

rare_text <- pdftools::pdf_text("https://cms.gruene.de/uploads/documents/2021_Wahlprogrammentwurf.pdf")
bad <- hunspell::hunspell(rare_text, dict = "de_DE")

```

```{r}
EU.tweets.df2 <- EU.tweets.df %>%
  unnest_tokens(word, text)
dim(EU.tweets.df)
dim(EU.tweets.df2)
```
```{r}
EU.tweets.df2 %>%
  dplyr::count(word, sort = TRUE) %>%
  filter(n > 80) %>%
  dplyr::mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +geom_col() +xlab(NULL) +coord_flip()
```

```{r}
EU.tweets.df2 <- EU.tweets.df2 %>%
  anti_join(stop_words)

head(EU.tweets.df2 %>%
       dplyr::count(word, sort = TRUE))
```

```{r}
custom.stop.words <- bind_rows(data_frame(word = c("https", "t.co", "amp"),lexicon = c("custom", "custom", "custom")),stop_words)
EU.tweets.df2 <- EU.tweets.df2 %>%
  anti_join(custom.stop.words)

head(EU.tweets.df2 %>%
       dplyr::count(word, sort = TRUE))
```

```{r}
EU.tweets.df2 %>%
  dplyr::count(word, sort = TRUE) %>%
  filter(n>50) %>%
  dplyr::mutate(word =reorder(word, n)) %>%
  ggplot(aes(word, n)) +geom_col() +xlab(NULL) +coord_flip()
```

```{r}
EU.tweets.df2 %>%
  anti_join(stop_words) %>%
  anti_join(custom.stop.words) %>%
  dplyr::count(word) %>%
  with(wordcloud(word, n, max.words = 100,main = "Wordcloud"))
```
```{r}
stems <- unlist(hunspell_stem(unlist(EU.tweets.df2$word)))
words <- sort(table(stems), decreasing = TRUE)
print(head(words, 5))

EU.words <- sort(table(EU.tweets.df2$word), decreasing = TRUE)print(head(EU.words, 5))
```

```{r}
library(stringr)
nrc.positive <- get_sentiments("nrc") %>%
  filter(sentiment == "positive")head(nrc.positive)
```

```{r}
nrc.negative <- get_sentiments("nrc") %>%
  filter(sentiment == "negative")

head(EU.tweets.df2 %>%
       inner_join(nrc.negative) %>%
       dplyr::count(word, sort = TRUE))
```

```{r}
bing.word.counts <- EU.tweets.df2 %>%
  inner_join(get_sentiments("bing")) %>%
  dplyr::count(word, sentiment, sort = TRUE) %>%
  ungroup()

head(bing.word.counts)
```

```{r}
bing.word.counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  dplyr::mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +geom_col(show.legend = FALSE) +facet_wrap(~sentiment, scales = "free_y") +labs(y = "Contribution to sentiment",x = NULL) +coord_flip()
```

```{r}
library(reshape2)
EU.tweets.df2 %>%
  inner_join(get_sentiments("bing")) %>%
  dplyr::count(word, sentiment, sort = TRUE) %>%
  acast(word~sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors =c("#F8766D", "#00BFC4"),max.words = 30)
```

```{r}
library
EU.tweets.df2_dtm <- EU.tweets.df2 %>%
  dplyr::count(status_id, word) %>%
  ungroup() %>%
  cast_dtm(status_id, word, n)
```

```{r}
Korrelationen <- findAssocs(EU.tweets.df2_dtm,terms=c("euro", "conference", "insolvency"),corlimit=0.4)
```

```{r}
library(Rgraphviz)
plot(EU.tweets.df2_dtm, corThreshold = 0.2,weighting=TRUE,terms = findFreqTerms(EU.tweets.df2_dtm, 80, Inf),main = "Wortzusammenhaenge")
```


```{r}
termDocMatrix <- as.matrix(t(EU.tweets.df2_dtm))
termDocMatrix[termDocMatrix >= 1] <- 1
termMatrix <- termDocMatrix %*% t(termDocMatrix)
termMatrix <- termMatrix[1:20,1:20]termMatrix[1:3,1:3]
```

```{r}
EU.bigrams <- EU.tweets.df %>%
  select_if(~ !is.list(.)) %>%
  unnest_tokens(word, text,token="ngrams",n=2)EU.bigrams$word[1:3]
```

```{r}
EU.bigrams %>%
  dplyr::count(word, sort = TRUE) %>%
  filter(n>40) %>%
  mutate(word =reorder(word, n)) %>%
  ggplot(aes(word, n)) +geom_col() +xlab(NULL) +coord_flip()
```


```{r}
library(igraph)
g <- graph.adjacency(termMatrix, weighted=T, mode = "undirected")
g <- simplify(g)
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)
layout1 <- layout.fruchterman.reingold(g)
plot(g, layout=layout1)

```

```{r}
library(tidyr)
bigrams_separated <- EU.bigrams %>%
  tidyr::separate(word,c("word1", "word2"), sep = " ")

bigrams_separated$word1[1:3]
```

```{r}
bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)
bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% custom.stop.words$word) %>%
  filter(!word2 %in% custom.stop.words$word)
bigram_counts <- bigrams_filtered %>%
  dplyr::count(word1, word2, sort = TRUE)head(bigram_counts)
```

```{r}
bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")
```

```{r}
bigrams_separated %>%
  filter(word1=="not") %>%
  dplyr::count(word1, word2, sort = TRUE)
```

```{r}
bigram_graph <- bigram_counts %>%
  filter(n>40) %>%
  graph_from_data_frame()

bigram_graph
```

```{r}
ggraph(bigram_graph, layout = "fr") + geom_edge_link() + geom_node_point() + geom_node_text(aes(label = name), vjust = 1, hjust = 1,cex = 5.3)
```

```{r}
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph, layout = "fr") + geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,arrow = a, end_cap = circle(.07, ’inches’)) + geom_node_point(color = "lightblue", size = 5) + geom_node_text(aes(label = name), vjust = 1, hjust = 1,cex=5.3) + theme_void()
```

```{r}
library(twitteR)
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)

numberFollowers = 1000
EU <- twitteR::getUser("EUCouncilPress")
EU.followers <- EU$getFollowers(numberFollowers)
EU.followers[[1]]
```

```{r}
library(maps)
library(geosphere)
data(world.cities)
data(us.cities)
data(canada.cities)
data(worldMapEnv)

maps::map('world', col = "#191919",bg = "grey",fill = T,mar = rep(0,4),border = 0)
```

```{r}
numberFollowers = 500
map('world', col = "#191919",bg = "grey", fill = T,mar = rep(0,4), border = 0)
tf.list <- list(rep(0,numberFollowers))

for (i in 1:numberFollowers) {
  tf.list[i] <- EU.followers[[i]]$getLocation()
}

for (i in 1:numberFollowers) {
  points(findLatLon(tf.list[[i]][1])$latlon,col = "blue", lwd = 0.2,pch = 16, cex = 0.7)
}
```

```{r}
library(OpenStreetMap)
library(osmar)
library(maps)
library(plyr)

mapBing <- OpenStreetMap::openmap(c(33.760525217369974, -118.22052955627441),c(33.73290566922855, -118.17521095275879), type = "bing")

plot(mapBing, raster = TRUE)

loadedNamespaces()
```

```{r}
TrierBing <- OpenStreetMap::openmap(c(49.76864, 6.628274),c(49.74955, 6.657019),type = "bing")

plot(TrierBing,raster = TRUE)
```


